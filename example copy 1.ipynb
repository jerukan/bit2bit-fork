{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, traceback\n",
    "# orig = getattr(torch._C, \"_cuda_init\", None)\n",
    "# def _wrapped_cuda_init():\n",
    "#     print(\"=== torch._C._cuda_init called ===\")\n",
    "#     traceback.print_stack(limit=8)\n",
    "#     if orig:\n",
    "#         orig()\n",
    "# torch._C._cuda_init = _wrapped_cuda_init\n",
    "\n",
    "\n",
    "from spadio import SPADFolder, SPADData  # noqa\n",
    "from spadclean import GenerateTestData, SPADHotpixelTool  # noqa\n",
    "from pathlib import Path\n",
    "from utils import clean_hotpixels\n",
    "from inference import cpu_inference\n",
    "from metadata import TrainData, ModelConfig, TrainConfig, load_config\n",
    "from dataset import (\n",
    "    BernoulliDataset3D,\n",
    "    ValidationDataset3D,\n",
    "    PairedDataset,\n",
    "    BinomDataset3D,\n",
    "    N2NDataset3D,\n",
    ")  # noqa\n",
    "from spadgapmodels import SPADGAP\n",
    "import torch\n",
    "import torch.utils.data as dt\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    DeviceStatsMonitor,\n",
    ")\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from tifffile import imwrite, imread\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_from_dcr(dcr_rate_hz, fps):\n",
    "    \"\"\"\n",
    "    Convert a dark count rate in Hz to a per-frame probability of a dark count photon.\n",
    "    \"\"\"\n",
    "    return 1 - np.exp(-dcr_rate_hz / fps)\n",
    "\n",
    "def thin_frames_uniform(frames, keep_prob, dcr_prob=None, seed=None):\n",
    "    \"\"\"\n",
    "    Thin binary frames uniformly with probability keep_prob. Also adds dark\n",
    "    count photons to lower the SNR.\n",
    "\n",
    "    This is an expensive operation on SPAD data, so dask is used for\n",
    "    multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        dcr_prob: dark count photon probability (not the rate itself)\n",
    "    \"\"\"\n",
    "    T, H, W = frames.shape\n",
    "    # convert to a dask array with automatic chunking and apply a lazy random mask\n",
    "    frames = da.from_array(frames, chunks=(400, H, W))\n",
    "    rs = da.random.RandomState(seed)\n",
    "    mask = rs.random_sample(frames.shape, chunks=frames.chunks) < keep_prob\n",
    "    if dcr_prob is not None:\n",
    "        dcr_photons = rs.binomial(1, dcr_prob, size=frames.shape, chunks=frames.chunks).astype(\"uint8\")\n",
    "    else:\n",
    "        dcr_photons = da.zeros(frames.shape, chunks=frames.chunks, dtype=\"uint8\")\n",
    "    frames = (frames.astype(\"uint8\") & mask.astype(\"uint8\")) | dcr_photons\n",
    "    return frames.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_path = Path(\"./config.yml\")\n",
    "config = load_config(path=configure_path)  # CLI argument\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     # filename=config[\"PATH\"][\"logger\"],\n",
    "#     level=logging.DEBUG,\n",
    "#     format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "#     stream=sys.stdout,\n",
    "# )\n",
    "\n",
    "data_type = config[\"PATH\"][\"data_type\"]\n",
    "if data_type not in [\"raw\", \"processed\"]:\n",
    "    raise ValueError(\"Data type must be RAW or CLEAN\")\n",
    "\n",
    "dir_path = Path(config[\"PATH\"][\"dir_path\"])\n",
    "num_of_files = config[\"PATH\"][\"num_of_files\"]\n",
    "data_dir = Path(config[\"PATH\"][\"data_dir\"])\n",
    "data_path = config[\"PATH\"][\"data_path\"]\n",
    "data_file = config[\"PATH\"][\"data_file\"]\n",
    "ground_truth_path = config[\"PATH\"][\"ground_truth_path\"]\n",
    "ground_truth_file = config[\"PATH\"][\"ground_truth_file\"]\n",
    "model_path = Path(config[\"PATH\"][\"model_path\"])\n",
    "\n",
    "data_path = data_dir / data_file if data_path == \"\" else Path(data_path)\n",
    "ground_truth_path = (\n",
    "    data_dir / ground_truth_file if ground_truth_path == \"\" else Path(ground_truth_path)\n",
    ")\n",
    "if data_type == \"raw\":\n",
    "    try:\n",
    "        if dir_path.is_dir():\n",
    "            input_folder = SPADFolder(dir_path)\n",
    "            input = input_folder.spadstack[:num_of_files]\n",
    "            data = input.process(clean_hotpixels)\n",
    "        else:\n",
    "            input_folder = SPADData(dir_path)\n",
    "            input = input_folder.data\n",
    "            data = clean_hotpixels(input)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(\"Folder not found\")\n",
    "        # sys.exit(1)\n",
    "    del input\n",
    "elif data_type == \"processed\":\n",
    "    try:\n",
    "        data = imread(data_path)\n",
    "        ground_truth_file = imread(ground_truth_path)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(\"File not found\")\n",
    "        # sys.exit(1)\n",
    "\n",
    "data = data[:40000]\n",
    "keep_prob = config[\"PATH\"][\"thin\"]\n",
    "if keep_prob < 1.0:\n",
    "    data = thin_frames_uniform(data, keep_prob=keep_prob, seed=42)\n",
    "idx_train = int(data.shape[0] * 0.8)\n",
    "data_config = TrainData.from_config(config[\"DATA\"], data[:idx_train].astype(np.float32))\n",
    "model_config = ModelConfig.from_config(config[\"MODEL\"])\n",
    "train_config = TrainConfig.from_config(config[\"TRAINING\"], data_config, model_config)\n",
    "val_data_config = TrainData.from_config_validation(\n",
    "    config[\"DATA\"], (data[idx_train:].astype(np.float32))\n",
    ")\n",
    "print(train_config.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = BernoulliDataset3D.from_dataclass(data_config)\n",
    "val_data = ValidationDataset3D.from_dataclass(val_data_config)\n",
    "\n",
    "loader_config = {\n",
    "    \"batch_size\": train_config.batch_size,\n",
    "    \"shuffle\": train_config.shuffle,\n",
    "    \"pin_memory\": train_config.pin_memory,\n",
    "    \"drop_last\": train_config.drop_last,\n",
    "    \"num_workers\": train_config.num_workers,\n",
    "    \"persistent_workers\": True,\n",
    "}\n",
    "\n",
    "train_loader = dt.DataLoader(train_data, **loader_config)\n",
    "loader_config[\"shuffle\"] = False\n",
    "val_loader = dt.DataLoader(val_data, **loader_config)\n",
    "\n",
    "test_name = train_config.name\n",
    "default_root_dir = model_path / test_name\n",
    "if not default_root_dir.exists():\n",
    "    default_root_dir.mkdir(parents=True)\n",
    "\n",
    "model = SPADGAP.from_dataclass(model_config)\n",
    "model.train()\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=model_path, name=test_name)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=default_root_dir,\n",
    "    accelerator=\"gpu\",\n",
    "    gradient_clip_val=1,\n",
    "    precision=train_config.precision,  # type: ignore\n",
    "    devices=[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    strategy=\"ddp_find_unused_parameters_true\",\n",
    "    max_epochs=train_config.epochs,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            save_weights_only=True,\n",
    "            mode=\"min\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_top_k=2,\n",
    "        ),\n",
    "        LearningRateMonitor(\"epoch\"),\n",
    "        # EarlyStopping(\"val_loss\", patience=25),\n",
    "        # DeviceStatsMonitor(),\n",
    "    ],\n",
    "    logger=logger,  # type: ignore\n",
    "    profiler=\"simple\",\n",
    "    limit_val_batches=20,\n",
    "    enable_model_summary=True,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "# print(f\"input_size: {tuple(next(iter(train_loader))[0].shape)}\")\n",
    "print(f\"file: {test_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchinfo\n",
    "# torchinfo.summary(model, input_size=(train_config.batch_size, 1, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "train_config.to_yaml(default_root_dir / \"metadata.yml\")\n",
    "shutil.copyfile(configure_path, default_root_dir / \"config.yml\")\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.save_checkpoint(default_root_dir / \"final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_checkpoint(default_root_dir / \"final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import clear_vram  \n",
    "# clear_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_split = np.random.binomial(data, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitted_inference = []\n",
    "# for i in range(0, 10):\n",
    "#     data_split = np.random.binomial(data, 0.9)\n",
    "#     output = gpu_patch_inference(\n",
    "#         model,\n",
    "#         data_split[:512].astype(np.float32),\n",
    "#         initial_patch_depth=48,\n",
    "#         min_overlap=40,\n",
    "#         device=train_config.device_number,\n",
    "#     )\n",
    "#     splitted_inference.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "def get_codec_for_format(format: str):\n",
    "    \"\"\"\n",
    "    Get appropriate fourcc codec string for given video format.\n",
    "    \"\"\"\n",
    "    format = format.lower()\n",
    "    if format == \"mp4\":\n",
    "        return \"mp4v\"\n",
    "    elif format == \"avi\":\n",
    "        return \"FFV1\"\n",
    "    elif format == \"mov\":\n",
    "        return \"avc1\"\n",
    "    else:\n",
    "        raise ValueError(f\"I haven't added the codec for: {format}\")\n",
    "def to_video(frames: np.ndarray, path, res_scale=1.0, playback_fps=None, cmap=None, format=None, maxv=None):\n",
    "    \"\"\"\n",
    "    Saves video frame arrays to a video file or sequence of PNGs. If path has no extension, \n",
    "    it is treated as a directory and individual image files are saved.\n",
    "\n",
    "    Args:\n",
    "        frames (np.ndarray): (T x H x W x C) (RGB) or (T x H x W) (intensity) video frames.\n",
    "        path (str or Path): output video file path or directory for image files.\n",
    "        res_scale (float): resolution scaling factor with nearest neighbor interpolation.\n",
    "        cmap: ignored if frames are RGB; otherwise, matplotlib colormap name or object.\n",
    "        format (str or None): video format (e.g., \"mp4\", \"avi\"), or image format (e.g., \"png\");\n",
    "            if None, inferred from path suffix.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if cmap is None:\n",
    "        cmap = \"viridis\"\n",
    "    cmap_fn = cm.get_cmap(cmap)\n",
    "    is_rgb = False\n",
    "    if frames.ndim == 4:\n",
    "        if frames.shape[3] == 3:\n",
    "            is_rgb = True\n",
    "        else:\n",
    "            raise ValueError(\"4D frames array must have shape (T, H, W, 3) for RGB video\")\n",
    "    elif frames.ndim == 3:\n",
    "        is_rgb = False\n",
    "    else:\n",
    "        raise ValueError(\"frames must be a 3D or 4D numpy array\")\n",
    "\n",
    "    # compute a normalized intensity in [0,1] for colormap input\n",
    "    if maxv is None:\n",
    "        maxv = float(np.max(frames))\n",
    "        if maxv == 0.0:\n",
    "            maxv = 1.0\n",
    "\n",
    "    H, W = frames.shape[1], frames.shape[2]\n",
    "    if res_scale != 1.0:\n",
    "        out_W = int(W * res_scale)\n",
    "        out_H = int(H * res_scale)\n",
    "    else:\n",
    "        out_W = W\n",
    "        out_H = H\n",
    "    # if path is a directory, write individual image files\n",
    "    is_video_file = path.suffix in [\".mp4\", \".avi\", \".mov\", \".mkv\"]\n",
    "    if not is_video_file:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        if format is None:\n",
    "            format = \"png\"\n",
    "    else:\n",
    "        if playback_fps is None:\n",
    "            raise ValueError(\"playback_fps must be specified if saving a video file\")\n",
    "        if format is None:\n",
    "            format = path.suffix[1:].lower()\n",
    "        codec = get_codec_for_format(format)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "        vidwriter = cv2.VideoWriter(str(path), fourcc, playback_fps, (out_W, out_H), isColor=True)\n",
    "\n",
    "    max_frames = len(frames)\n",
    "\n",
    "    for i in tqdm(range(max_frames), desc=\"Writing video frames\"):\n",
    "        intensity = np.clip(frames[i], 0, maxv) / maxv  # normalize to [0,1]\n",
    "        if is_rgb:\n",
    "            rgb_mapped = (intensity * 255.0).astype(np.uint8)  # (H,W,3) in RGB\n",
    "        else:\n",
    "            # apply matplotlib colormap -> returns RGBA in [0,1]\n",
    "            rgba_mapped = cmap_fn(intensity)  # shape (H,W,4)\n",
    "            rgb_mapped = (rgba_mapped[..., :3] * 255.0).astype(np.uint8)  # (H,W,3) in RGB\n",
    "        bgr_mapped = rgb_mapped[..., ::-1]  # convert to BGR for OpenCV\n",
    "        if res_scale != 1.0:\n",
    "            bgr_mapped = cv2.resize(bgr_mapped, (out_W, out_H), interpolation=cv2.INTER_NEAREST)\n",
    "        if is_video_file:\n",
    "            vidwriter.write(bgr_mapped)\n",
    "        else:\n",
    "            frame_path = path / f\"frame_{i:05d}.{format}\"\n",
    "            cv2.imwrite(str(frame_path), bgr_mapped)\n",
    "    if is_video_file:\n",
    "        vidwriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import gpu_patch_inference\n",
    "\n",
    "dataset = \"guitar-0.03125\"\n",
    "model = SPADGAP.load_from_checkpoint(f\"models/{dataset}/final_model.ckpt\")\n",
    "indata = data[:10000].astype(np.float32)\n",
    "output = gpu_patch_inference(\n",
    "    model,\n",
    "    indata,\n",
    "    initial_patch_depth=48,\n",
    "    min_overlap=40,\n",
    "    device=train_config.device_number,\n",
    ")\n",
    "resdir = Path(f\"results/{dataset}\")\n",
    "resdir.mkdir(parents=True, exist_ok=True)\n",
    "imwrite(resdir / \"input.tif\", indata)\n",
    "imwrite(resdir / \"inference.tif\", output)\n",
    "to_video(output, resdir / \"inference.avi\",  playback_fps=30, cmap=\"grey\")\n",
    "gamma = output ** (1/2.2)\n",
    "gamma14 = output ** (1/4.0)\n",
    "to_video(gamma, resdir / \"inference-gamma.avi\",  playback_fps=30, cmap=\"grey\")\n",
    "to_video(gamma14, resdir / \"inference-gamma-1-4.avi\",  playback_fps=30, cmap=\"grey\")\n",
    "to_video(gamma[::100], resdir / \"inference-gamma-fps1000.avi\",  playback_fps=30, cmap=\"grey\")\n",
    "to_video(gamma14[::100], resdir / \"inference-gamma-1-4-fps1000.avi\",  playback_fps=30, cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = imread(Path(\"results\") / \"inference.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(output.shape[0]) / 100_000, output[:, 50, 450])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "# plt.xlim(0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import group_metrics\n",
    "\n",
    "input = data[:512].astype(float)\n",
    "image = output\n",
    "ground_truth = ground_truth_file[:512].astype(float)\n",
    "group_metrics(input, image, ground_truth, default_root_dir, device=train_config.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
